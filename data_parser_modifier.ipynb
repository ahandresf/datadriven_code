{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Andres Felipe Alba Hernandez\n",
    "Applied AI Engineer <br>\n",
    "Created: March 2020 <br>\n",
    "Last Modified: April, 2020\n",
    "email: v-analba@microsoft.com <br>\n",
    "https://www.linkedin.com/in/ahandresf/\n",
    "\n",
    "\n",
    "The goal of this jupyter notebook is to function as a data parser from csv file that contain a time series of data from the process that may be controlled later by the BRAIN. This data will be feed to different ML models that may learn the dynamic of the system and generalize in order to be used as simulator of the process later. This will allow us to train the BRAIN (RL algorithm) using a simulator (data-driven model). <br>\n",
    "\n",
    "For this case:\n",
    "- With $p$ as the number of variables in the action space.\n",
    "- With $m$ as the number of variables in the state space. \n",
    "- Data input is a vector that concatanate the vetor $A$ and $S$  with  $A=a_{1_{n}},..a_{p_{n}}$ and  $S=s_{1_{n}}, ..., s_{m_{n}}$.\n",
    "- Data output correspond to state $S_{n+1}$ with $S=s_{1_{n+1}}, ..., s_{m_{n+1}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import csv\n",
    "import pprint\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parsing 2020 and create metadata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#provide the data directory\n",
    "data_dir='C:/Users/aalbaher/dataset_pttgc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!dir\n",
    "#initializing\n",
    "headers_dic={}\n",
    "short_list={}\n",
    "'''\n",
    "make sure your file is in the same folder of this jupyter notebook or provide \n",
    "the complete path to the file.\n",
    "'''\n",
    "file1='2020_Jan_March.csv'\n",
    "file2='2019_Dec.csv'\n",
    "file3='2019_Jan_Sep.csv'\n",
    "file4='2018_2019.csv'\n",
    "file5='2017_2018.csv'\n",
    "file6='2016_2017.csv'\n",
    "file_name1=('%s/%s')%(data_dir,file1)\n",
    "file_name2=('%s/%s')%(data_dir,file2)\n",
    "file_name3=('%s/%s')%(data_dir,file3)\n",
    "file_name4=('%s/%s')%(data_dir,file4)\n",
    "file_name5=('%s/%s')%(data_dir,file5)\n",
    "file_name6=('%s/%s')%(data_dir,file6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/aalbaher/dataset_pttgc/data_preprocess/May_13_165417/\n"
     ]
    }
   ],
   "source": [
    "#provide the data directory\n",
    "time_stamp=time.strftime('%B_%d_%H%M%S')\n",
    "data_out_dir=r'C:/Users/aalbaher/dataset_pttgc/data_preprocess/'+time_stamp+'/'\n",
    "os.makedirs(data_out_dir)\n",
    "print(data_out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create metadata\n",
    "Organize the metadata into a dictionary. This disctionary have some information that describe the each variable in the dataset. This variables will correspond later to most of the columns in a pandas data frame (except the first one that is time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the file object\n",
    "f=open(file_name1, newline='')\n",
    "reader = csv.reader(f)\n",
    "#getting metadata from the csv file, we skip first column. \n",
    "point_name = next(reader)[1::]\n",
    "description = next(reader)[1::]\n",
    "var_type = next(reader)[1::]\n",
    "priority = next(reader)[1::]\n",
    "units = next(reader)[1::]\n",
    "#print(point_name)\n",
    "#print(len(point_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dictionary of headers\n",
    "for i, var_name in enumerate(point_name):\n",
    "    headers_dic[var_name]={\n",
    "                     'description':description[i],\n",
    "                     'var_type':var_type[i],\n",
    "                     'priority':priority[i],\n",
    "                     'units':units[i],\n",
    "                     }\n",
    "    if priority[i]=='10':\n",
    "        short_list[var_name]=headers_dic[var_name]      \n",
    "#pprint.pprint(headers_dic)\n",
    "f.close() #close the file object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing Metadata as dictionary\n",
    "with open('headers_dic.json', 'w') as fp:\n",
    "    json.dump(headers_dic, fp, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building DataFrame\n",
    "Now, we put the data itself into a dataframe, the first column is the time and the others are the possible state variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/aalbaher/dataset_pttgc/2020_Jan_March.csv\n"
     ]
    }
   ],
   "source": [
    "#read the remaining data and put it in a pandas dataframe. \n",
    "print(file_name1)\n",
    "name_of_columns=['time']+point_name\n",
    "df1=pd.read_csv(file_name1,skiprows=5,names=name_of_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>14FIC015.MEAS</th>\n",
       "      <th>16FIC501.MEAS</th>\n",
       "      <th>14TI521.PNT</th>\n",
       "      <th>14PRCA502.MEAS</th>\n",
       "      <th>14FRC509.MEAS</th>\n",
       "      <th>14FRCA506.MEAS</th>\n",
       "      <th>14TI504.PNT</th>\n",
       "      <th>14TI532.PNT</th>\n",
       "      <th>14PRCA506.MEAS</th>\n",
       "      <th>...</th>\n",
       "      <th>14FRC514.MEAS</th>\n",
       "      <th>14FRC501.MEAS</th>\n",
       "      <th>14QI508.PNT</th>\n",
       "      <th>14TY513.RO01</th>\n",
       "      <th>14FIC503.MEAS</th>\n",
       "      <th>14TI502.PNT</th>\n",
       "      <th>16Q001.PNT</th>\n",
       "      <th>14QRA502.PNT</th>\n",
       "      <th>14Y559.RO01</th>\n",
       "      <th>14LRCA503.MEAS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1/1/2020 0:00</td>\n",
       "      <td>6452.264160</td>\n",
       "      <td>746.490967</td>\n",
       "      <td>293.762207</td>\n",
       "      <td>9.486253</td>\n",
       "      <td>491.542084</td>\n",
       "      <td>15.149858</td>\n",
       "      <td>104.698769</td>\n",
       "      <td>219.788117</td>\n",
       "      <td>0.581865</td>\n",
       "      <td>...</td>\n",
       "      <td>1423.786255</td>\n",
       "      <td>4644.759766</td>\n",
       "      <td>104.805008</td>\n",
       "      <td>74.106934</td>\n",
       "      <td>5917.788086</td>\n",
       "      <td>151.574768</td>\n",
       "      <td>0.245352</td>\n",
       "      <td>83.655220</td>\n",
       "      <td>4.234562</td>\n",
       "      <td>38.160904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1/1/2020 0:01</td>\n",
       "      <td>6435.390625</td>\n",
       "      <td>752.322998</td>\n",
       "      <td>293.757568</td>\n",
       "      <td>9.493867</td>\n",
       "      <td>491.384552</td>\n",
       "      <td>15.114125</td>\n",
       "      <td>104.686874</td>\n",
       "      <td>219.774994</td>\n",
       "      <td>0.579752</td>\n",
       "      <td>...</td>\n",
       "      <td>1431.386719</td>\n",
       "      <td>4652.797363</td>\n",
       "      <td>104.806519</td>\n",
       "      <td>74.132072</td>\n",
       "      <td>5919.329102</td>\n",
       "      <td>151.555176</td>\n",
       "      <td>0.245539</td>\n",
       "      <td>83.660782</td>\n",
       "      <td>4.387371</td>\n",
       "      <td>38.277836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1/1/2020 0:02</td>\n",
       "      <td>6435.275391</td>\n",
       "      <td>746.536194</td>\n",
       "      <td>293.771973</td>\n",
       "      <td>9.509203</td>\n",
       "      <td>489.817596</td>\n",
       "      <td>15.125778</td>\n",
       "      <td>104.680672</td>\n",
       "      <td>219.822266</td>\n",
       "      <td>0.575745</td>\n",
       "      <td>...</td>\n",
       "      <td>1434.629028</td>\n",
       "      <td>4647.533691</td>\n",
       "      <td>104.831047</td>\n",
       "      <td>74.102310</td>\n",
       "      <td>5926.901855</td>\n",
       "      <td>151.593780</td>\n",
       "      <td>0.245629</td>\n",
       "      <td>83.655670</td>\n",
       "      <td>4.284944</td>\n",
       "      <td>38.163483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1/1/2020 0:03</td>\n",
       "      <td>6486.708496</td>\n",
       "      <td>744.761047</td>\n",
       "      <td>293.793488</td>\n",
       "      <td>9.513070</td>\n",
       "      <td>488.737946</td>\n",
       "      <td>15.156744</td>\n",
       "      <td>104.508133</td>\n",
       "      <td>219.763351</td>\n",
       "      <td>0.575633</td>\n",
       "      <td>...</td>\n",
       "      <td>1438.131836</td>\n",
       "      <td>4649.957520</td>\n",
       "      <td>104.940735</td>\n",
       "      <td>74.064453</td>\n",
       "      <td>5932.580078</td>\n",
       "      <td>151.361084</td>\n",
       "      <td>0.245434</td>\n",
       "      <td>83.656097</td>\n",
       "      <td>4.321112</td>\n",
       "      <td>38.047146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1/1/2020 0:04</td>\n",
       "      <td>6438.978027</td>\n",
       "      <td>749.576538</td>\n",
       "      <td>293.801300</td>\n",
       "      <td>9.529663</td>\n",
       "      <td>492.406342</td>\n",
       "      <td>15.141134</td>\n",
       "      <td>104.603279</td>\n",
       "      <td>219.720276</td>\n",
       "      <td>0.577805</td>\n",
       "      <td>...</td>\n",
       "      <td>1429.786865</td>\n",
       "      <td>4646.831055</td>\n",
       "      <td>105.039764</td>\n",
       "      <td>74.064941</td>\n",
       "      <td>5930.948730</td>\n",
       "      <td>151.584259</td>\n",
       "      <td>0.245171</td>\n",
       "      <td>83.654572</td>\n",
       "      <td>4.384132</td>\n",
       "      <td>37.973122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98636</td>\n",
       "      <td>3/9/2020 11:56</td>\n",
       "      <td>6114.192383</td>\n",
       "      <td>675.065735</td>\n",
       "      <td>291.408081</td>\n",
       "      <td>9.645794</td>\n",
       "      <td>551.993408</td>\n",
       "      <td>11.042987</td>\n",
       "      <td>102.439766</td>\n",
       "      <td>218.786377</td>\n",
       "      <td>0.566735</td>\n",
       "      <td>...</td>\n",
       "      <td>1415.566162</td>\n",
       "      <td>4174.227051</td>\n",
       "      <td>104.912712</td>\n",
       "      <td>74.076981</td>\n",
       "      <td>5362.497559</td>\n",
       "      <td>149.020172</td>\n",
       "      <td>0.251332</td>\n",
       "      <td>83.771507</td>\n",
       "      <td>3.773265</td>\n",
       "      <td>37.616447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98637</td>\n",
       "      <td>3/9/2020 11:57</td>\n",
       "      <td>6111.750000</td>\n",
       "      <td>673.141907</td>\n",
       "      <td>291.323029</td>\n",
       "      <td>9.637948</td>\n",
       "      <td>548.302856</td>\n",
       "      <td>11.019686</td>\n",
       "      <td>102.205559</td>\n",
       "      <td>218.823013</td>\n",
       "      <td>0.565695</td>\n",
       "      <td>...</td>\n",
       "      <td>1427.341797</td>\n",
       "      <td>4148.922363</td>\n",
       "      <td>104.938042</td>\n",
       "      <td>74.089111</td>\n",
       "      <td>5354.990723</td>\n",
       "      <td>148.913574</td>\n",
       "      <td>0.251905</td>\n",
       "      <td>84.359352</td>\n",
       "      <td>3.808475</td>\n",
       "      <td>37.791866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98638</td>\n",
       "      <td>3/9/2020 11:58</td>\n",
       "      <td>6088.703613</td>\n",
       "      <td>678.479553</td>\n",
       "      <td>291.203247</td>\n",
       "      <td>9.653341</td>\n",
       "      <td>550.416992</td>\n",
       "      <td>10.999985</td>\n",
       "      <td>102.171616</td>\n",
       "      <td>218.841507</td>\n",
       "      <td>0.590596</td>\n",
       "      <td>...</td>\n",
       "      <td>1426.663818</td>\n",
       "      <td>4129.304199</td>\n",
       "      <td>104.648231</td>\n",
       "      <td>74.090919</td>\n",
       "      <td>5354.736816</td>\n",
       "      <td>148.873474</td>\n",
       "      <td>0.252462</td>\n",
       "      <td>84.366898</td>\n",
       "      <td>3.800796</td>\n",
       "      <td>37.853031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98639</td>\n",
       "      <td>3/9/2020 11:59</td>\n",
       "      <td>6085.645020</td>\n",
       "      <td>674.612854</td>\n",
       "      <td>291.110992</td>\n",
       "      <td>9.672322</td>\n",
       "      <td>553.572388</td>\n",
       "      <td>11.011888</td>\n",
       "      <td>102.007462</td>\n",
       "      <td>218.840713</td>\n",
       "      <td>0.609518</td>\n",
       "      <td>...</td>\n",
       "      <td>1441.762695</td>\n",
       "      <td>4116.078125</td>\n",
       "      <td>104.372345</td>\n",
       "      <td>74.097313</td>\n",
       "      <td>5365.450195</td>\n",
       "      <td>148.804611</td>\n",
       "      <td>0.253125</td>\n",
       "      <td>84.369316</td>\n",
       "      <td>3.778753</td>\n",
       "      <td>37.766796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98640</td>\n",
       "      <td>3/9/2020 12:00</td>\n",
       "      <td>6088.931152</td>\n",
       "      <td>677.160828</td>\n",
       "      <td>291.025879</td>\n",
       "      <td>9.682689</td>\n",
       "      <td>553.076233</td>\n",
       "      <td>11.019731</td>\n",
       "      <td>102.006760</td>\n",
       "      <td>218.820526</td>\n",
       "      <td>0.613169</td>\n",
       "      <td>...</td>\n",
       "      <td>1385.240967</td>\n",
       "      <td>4106.969727</td>\n",
       "      <td>104.123055</td>\n",
       "      <td>74.077553</td>\n",
       "      <td>5378.791992</td>\n",
       "      <td>148.879517</td>\n",
       "      <td>0.253648</td>\n",
       "      <td>84.367691</td>\n",
       "      <td>3.775685</td>\n",
       "      <td>37.568619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98641 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time  14FIC015.MEAS  16FIC501.MEAS  14TI521.PNT  \\\n",
       "0       1/1/2020 0:00    6452.264160     746.490967   293.762207   \n",
       "1       1/1/2020 0:01    6435.390625     752.322998   293.757568   \n",
       "2       1/1/2020 0:02    6435.275391     746.536194   293.771973   \n",
       "3       1/1/2020 0:03    6486.708496     744.761047   293.793488   \n",
       "4       1/1/2020 0:04    6438.978027     749.576538   293.801300   \n",
       "...               ...            ...            ...          ...   \n",
       "98636  3/9/2020 11:56    6114.192383     675.065735   291.408081   \n",
       "98637  3/9/2020 11:57    6111.750000     673.141907   291.323029   \n",
       "98638  3/9/2020 11:58    6088.703613     678.479553   291.203247   \n",
       "98639  3/9/2020 11:59    6085.645020     674.612854   291.110992   \n",
       "98640  3/9/2020 12:00    6088.931152     677.160828   291.025879   \n",
       "\n",
       "       14PRCA502.MEAS  14FRC509.MEAS  14FRCA506.MEAS  14TI504.PNT  \\\n",
       "0            9.486253     491.542084       15.149858   104.698769   \n",
       "1            9.493867     491.384552       15.114125   104.686874   \n",
       "2            9.509203     489.817596       15.125778   104.680672   \n",
       "3            9.513070     488.737946       15.156744   104.508133   \n",
       "4            9.529663     492.406342       15.141134   104.603279   \n",
       "...               ...            ...             ...          ...   \n",
       "98636        9.645794     551.993408       11.042987   102.439766   \n",
       "98637        9.637948     548.302856       11.019686   102.205559   \n",
       "98638        9.653341     550.416992       10.999985   102.171616   \n",
       "98639        9.672322     553.572388       11.011888   102.007462   \n",
       "98640        9.682689     553.076233       11.019731   102.006760   \n",
       "\n",
       "       14TI532.PNT  14PRCA506.MEAS  ...  14FRC514.MEAS  14FRC501.MEAS  \\\n",
       "0       219.788117        0.581865  ...    1423.786255    4644.759766   \n",
       "1       219.774994        0.579752  ...    1431.386719    4652.797363   \n",
       "2       219.822266        0.575745  ...    1434.629028    4647.533691   \n",
       "3       219.763351        0.575633  ...    1438.131836    4649.957520   \n",
       "4       219.720276        0.577805  ...    1429.786865    4646.831055   \n",
       "...            ...             ...  ...            ...            ...   \n",
       "98636   218.786377        0.566735  ...    1415.566162    4174.227051   \n",
       "98637   218.823013        0.565695  ...    1427.341797    4148.922363   \n",
       "98638   218.841507        0.590596  ...    1426.663818    4129.304199   \n",
       "98639   218.840713        0.609518  ...    1441.762695    4116.078125   \n",
       "98640   218.820526        0.613169  ...    1385.240967    4106.969727   \n",
       "\n",
       "       14QI508.PNT  14TY513.RO01  14FIC503.MEAS  14TI502.PNT  16Q001.PNT  \\\n",
       "0       104.805008     74.106934    5917.788086   151.574768    0.245352   \n",
       "1       104.806519     74.132072    5919.329102   151.555176    0.245539   \n",
       "2       104.831047     74.102310    5926.901855   151.593780    0.245629   \n",
       "3       104.940735     74.064453    5932.580078   151.361084    0.245434   \n",
       "4       105.039764     74.064941    5930.948730   151.584259    0.245171   \n",
       "...            ...           ...            ...          ...         ...   \n",
       "98636   104.912712     74.076981    5362.497559   149.020172    0.251332   \n",
       "98637   104.938042     74.089111    5354.990723   148.913574    0.251905   \n",
       "98638   104.648231     74.090919    5354.736816   148.873474    0.252462   \n",
       "98639   104.372345     74.097313    5365.450195   148.804611    0.253125   \n",
       "98640   104.123055     74.077553    5378.791992   148.879517    0.253648   \n",
       "\n",
       "       14QRA502.PNT  14Y559.RO01  14LRCA503.MEAS  \n",
       "0         83.655220     4.234562       38.160904  \n",
       "1         83.660782     4.387371       38.277836  \n",
       "2         83.655670     4.284944       38.163483  \n",
       "3         83.656097     4.321112       38.047146  \n",
       "4         83.654572     4.384132       37.973122  \n",
       "...             ...          ...             ...  \n",
       "98636     83.771507     3.773265       37.616447  \n",
       "98637     84.359352     3.808475       37.791866  \n",
       "98638     84.366898     3.800796       37.853031  \n",
       "98639     84.369316     3.778753       37.766796  \n",
       "98640     84.367691     3.775685       37.568619  \n",
       "\n",
       "[98641 rows x 39 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a new column that is a timestamp created from the string of date time provided in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remember it is month/day/year Hours:Minutes\n",
    "df1['timestamp']=df1['time'].apply(lambda x: datetime.strptime(x,'%m/%d/%Y %H:%M' ).timestamp())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Driven Model Input\n",
    "Building the numpy array that is expected by the data driven model. <br>\n",
    "\n",
    "The model expect to have X (input) and Y (output), where X is the actions vector concatenated with the input state vector, while Y is the output, state vector.\n",
    "\n",
    "```x_set = np.empty(shape=(total_sample, int(action_space_dim+state_space_dim)))\n",
    "y_set = np.empty(shape=(total_sample, int(state_space_dim)))\n",
    "```\n",
    "\n",
    "For our case the input would be one row, and the output will be the next row removing all the Manipulated variables (MV). These variables can be located as variable type == MV in the metadata dictionary. All the others variables are going to be consider state variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['14FICA508.MEAS', '14FICA508.SPT', '14TRC515.MEAS', '14TRC515.SPT', '14FRCA513.MEAS', '14FRCA513.SPT', '14FRCA511.MEAS', '14FRCA511.SPT']\n"
     ]
    }
   ],
   "source": [
    "action_names=[]\n",
    "for key in headers_dic:\n",
    "    if headers_dic[key]['var_type']=='MV':\n",
    "        action_names.append(key)\n",
    "print(action_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['14FICA508.MEAS', '14FICA508.SPT', '14TRC515.MEAS', '14TRC515.SPT', '14FRCA513.MEAS', '14FRCA513.SPT', '14FRCA511.MEAS', '14FRCA511.SPT', 'time', 'timestamp']\n"
     ]
    }
   ],
   "source": [
    "#df.drop(action_names+['time'],axis=1).loc[0,:] #checking if it is the right data frame\n",
    "'''\n",
    "create a list with the columns that will NOT belong to the state variables\n",
    "'''\n",
    "#With time stamps\n",
    "#drop_list=action_names+['time']\n",
    "\n",
    "#without timestamps\n",
    "drop_list=action_names+['time']+['timestamp']\n",
    "print(drop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['14FIC015.MEAS' '16FIC501.MEAS' '14TI521.PNT' '14PRCA502.MEAS'\n",
      " '14FRC509.MEAS' '14FRCA506.MEAS' '14TI504.PNT' '14TI532.PNT'\n",
      " '14PRCA506.MEAS' '10FRCA505.MEAS' '14FICA508.MD' '14TRC515.MD'\n",
      " '14FRCA513.MD' '14FRCA511.MD' '14TIC527.MEAS' '14QI506.PNT'\n",
      " '14FRC514.OUT' '14FRC501.OUT' '14TI535.MEAS' '14TI528.PNT'\n",
      " '14FRC514.MEAS' '14FRC501.MEAS' '14QI508.PNT' '14TY513.RO01'\n",
      " '14FIC503.MEAS' '14TI502.PNT' '16Q001.PNT' '14QRA502.PNT' '14Y559.RO01'\n",
      " '14LRCA503.MEAS']\n"
     ]
    }
   ],
   "source": [
    "#print(action_names)\n",
    "state_names=np.array(df1.drop(drop_list,axis=1).columns)\n",
    "print(state_names)\n",
    "np.save('state_names',state_names)\n",
    "np.save('action_names',action_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### December Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.read_csv(file_name2,skiprows=5,names=name_of_columns)\n",
    "df2['timestamp']=df2['time'].apply(lambda x: datetime.strptime(x,'%m/%d/%Y %H:%M').timestamp())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jan-Sep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=pd.read_csv(file_name3,skiprows=5,names=name_of_columns)\n",
    "df3['timestamp']=df3['time'].apply(lambda x: datetime.strptime(x,'%m/%d/%Y %H:%M').timestamp())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=pd.read_csv(file_name4,skiprows=5,names=name_of_columns)\n",
    "df4['timestamp']=df4['time'].apply(lambda x: datetime.strptime(x,'%m/%d/%Y %H:%M').timestamp())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5=pd.read_csv(file_name5,skiprows=5,names=name_of_columns)\n",
    "df5['timestamp']=df5['time'].apply(lambda x: datetime.strptime(x,'%m/%d/%Y %H:%M').timestamp())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6=pd.read_csv(file_name6,skiprows=5,names=name_of_columns)\n",
    "df6['timestamp']=df3['time'].apply(lambda x: datetime.strptime(x,'%m/%d/%Y %H:%M').timestamp())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store Pandas Data Frame in Disk\n",
    "\n",
    "We would probably like to have the data organized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new dataframe with the [timestamp,actions,states]\n",
    "new_col=['time']+['timestamp']+list(action_names)+list(state_names)\n",
    "#print(new_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf1=df1[new_col]\n",
    "ndf2=df2[new_col]\n",
    "ndf3=df3[new_col]\n",
    "ndf4=df4[new_col]\n",
    "ndf5=df5[new_col]\n",
    "ndf6=df6[new_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1/2020 0:00\n",
      "3/9/2020 12:00\n",
      "12/1/2019 0:00\n",
      "1/1/2020 11:42\n",
      "1/1/2019 0:00\n",
      "9/1/2019 12:00\n",
      "1/1/2018 0:00\n",
      "1/1/2019 0:00\n",
      "1/1/2017 0:00\n",
      "1/1/2018 12:00\n",
      "1/1/2016 0:00\n",
      "1/1/2017 0:00\n"
     ]
    }
   ],
   "source": [
    "#understanding the order on the dataset\n",
    "print(ndf1.iloc[0,:]['time'])\n",
    "print(ndf1.iloc[-1,:]['time'])\n",
    "print(ndf2.iloc[0,:]['time'])\n",
    "print(ndf2.iloc[-1,:]['time'])\n",
    "print(ndf3.iloc[0,:]['time'])\n",
    "print(ndf3.iloc[-1,:]['time'])\n",
    "print(ndf4.iloc[0,:]['time'])\n",
    "print(ndf4.iloc[-1,:]['time'])\n",
    "print(ndf5.iloc[0,:]['time'])\n",
    "print(ndf5.iloc[-1,:]['time'])\n",
    "print(ndf6.iloc[0,:]['time'])\n",
    "print(ndf6.iloc[-1,:]['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The first row is the earliest date, the last row is the latest date.\n",
    "ndf1=2020 data (newer)\n",
    "ndf2=2019 data (older)\n",
    "vertical_stack = pd.concat([older, newer], axis=0)\n",
    "vertical_stack = pd.concat([top, bottom], axis=0)\n",
    "\n",
    "'''\n",
    "vertical_stack = pd.concat([ndf6,ndf5,ndf4,ndf3,ndf2,ndf1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2073588, 40)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertical_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/aalbaher/dataset_pttgc/data_preprocess/May_13_165417/data.csv\n"
     ]
    }
   ],
   "source": [
    "dataset_name=('%sdata.csv'%(data_out_dir))\n",
    "print(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing vertical stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing all the data into a csv file, the data is all concatenated and organized in this way.\n",
    "#'time','timestamp',actions,states\n",
    "vertical_stack.to_csv(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create inputs with the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_input=np.array(vertical_stack[action_names].iloc[0:len(vertical_stack)-1,:]) #skip last row\n",
    "state_input=np.array(vertical_stack[state_names].iloc[0:len(vertical_stack)-1,:]) #skip last row\n",
    "state_output=np.array(vertical_stack[state_names].iloc[1::,:]) #skip fist row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2073587, 8)\n",
      "(2073587, 30)\n",
      "(2073587, 30)\n"
     ]
    }
   ],
   "source": [
    "print(action_input.shape)\n",
    "print(state_input.shape)\n",
    "print(state_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_set_total = np.concatenate((action_input,state_input),axis=1)\n",
    "y_set_total = state_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing dataset into disk\n",
    "file_x=('%sx_set_total.pickle'%(data_out_dir))\n",
    "file_y=('%sy_set_total.pickle'%(data_out_dir))\n",
    "with open('x_set_total.pickle', 'wb') as f:\n",
    "    pickle.dump(x_set_total, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open('y_set_total.pickle', 'wb') as f:\n",
    "    pickle.dump(y_set_total, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create output as difference between states\n",
    "\n",
    "Given that some of the models are not learning properly from the timeseries, we may need need to predict the difference instead of the the actual value. <br>\n",
    "\n",
    "- the input is $\\vec{X}=[ \\vec{a_{n}},\\vec{s_{n}} ]$ <br>\n",
    "- the output is  $\\vec{Y}=\\vec{s_{n+1}}-\\vec{s_{n}}$ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_set_diff=x_set_total\n",
    "y_set_diff=state_output-state_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing dataset into disk\n",
    "file_x_diff=('%sx_set_total.pickle'%(data_out_dir))\n",
    "file_y_diff=('%sy_set_total.pickle'%(data_out_dir))\n",
    "with open(file_x_diff, 'wb') as f:\n",
    "    pickle.dump(x_set_diff, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(file_y_diff, 'wb') as f:\n",
    "    pickle.dump(y_set_diff, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing code\n",
    "\n",
    "Everything below this point can be ignore, it was use during the develop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 12, 1, 12, 46)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t='12/1/2019 12:46:00 AM'\n",
    "datetime.strptime(t,'%m/%d/%Y %H:%M:%S %p')\n",
    "#datetime.strptime(df2['time'][46],'%m/%d/%Y %H:%M %p')\n",
    "#df2['time'][46]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting priority var names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "#short_list={}\n",
    "#print(headers_dic)\n",
    "print(len(short_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#First try\\nvar_dic={\\n    'state_var':{\\n                'C5_LPG':'16Q001.PNT',\\n                'LN_RVP':'14QRA502.PNT',\\n                'LN_95':'14QI506.PNT',\\n                'HN_10':'14QI508.PNT',\\n                'Reflux_dist_ratio':'14Y559.RO01',\\n                'LN_valve':'14FRC514.OUT',\\n                'HN_valve':'14FRC501.OUT',\\n                'LPG_dist_flow':'14FRC509.MEAS',\\n                'LN_dist_flow':'14FRC514.MEAS',\\n                },\\n         \\n    'action_var':{\\n                'C1451_reflux ':'14FICA508.MEAS',\\n                'Tray_5':'14TI528.PNT',\\n                'C1452_reflux':'14FRCA513.MEAS',\\n                'MPS_Steam':'14FRCA511.MEAS'\\n                },\\n         \\n     'predict_var':'14FRC501.MEAS'\\n    }\\n\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Second Try\n",
    "var_dic={\n",
    "    'state_var':{\n",
    "                'C5_LPG':'16Q001.PNT',\n",
    "                'LN_RVP':'14QRA502.PNT',\n",
    "                'LN_95':'14QI506.PNT',\n",
    "                'HN_10':'14QI508.PNT',\n",
    "                'LN_valve':'14FRC514.OUT',\n",
    "                'HN_valve':'14FRC501.OUT',\n",
    "                'LPG_dist_flow':'14FRC509.MEAS',\n",
    "                'LN_dist_flow':'14FRC514.MEAS',\n",
    "                },\n",
    "         \n",
    "    'action_var':{\n",
    "                'C1451_reflux ':'14FICA508.MEAS',\n",
    "                'Tray_5':'14TI528.PNT',\n",
    "                'C1452_reflux':'14FRCA513.MEAS',\n",
    "                'MPS_Steam':'14FRCA511.MEAS'\n",
    "                },\n",
    "         \n",
    "     'predict_var':'14FRC501.MEAS'\n",
    "    }\n",
    "\n",
    "'''\n",
    "#First try\n",
    "var_dic={\n",
    "    'state_var':{\n",
    "                'C5_LPG':'16Q001.PNT',\n",
    "                'LN_RVP':'14QRA502.PNT',\n",
    "                'LN_95':'14QI506.PNT',\n",
    "                'HN_10':'14QI508.PNT',\n",
    "                'Reflux_dist_ratio':'14Y559.RO01',\n",
    "                'LN_valve':'14FRC514.OUT',\n",
    "                'HN_valve':'14FRC501.OUT',\n",
    "                'LPG_dist_flow':'14FRC509.MEAS',\n",
    "                'LN_dist_flow':'14FRC514.MEAS',\n",
    "                },\n",
    "         \n",
    "    'action_var':{\n",
    "                'C1451_reflux ':'14FICA508.MEAS',\n",
    "                'Tray_5':'14TI528.PNT',\n",
    "                'C1452_reflux':'14FRCA513.MEAS',\n",
    "                'MPS_Steam':'14FRCA511.MEAS'\n",
    "                },\n",
    "         \n",
    "     'predict_var':'14FRC501.MEAS'\n",
    "    }\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state_var': {'C5_LPG': '16Q001.PNT',\n",
       "  'LN_RVP': '14QRA502.PNT',\n",
       "  'LN_95': '14QI506.PNT',\n",
       "  'HN_10': '14QI508.PNT',\n",
       "  'LN_valve': '14FRC514.OUT',\n",
       "  'HN_valve': '14FRC501.OUT',\n",
       "  'LPG_dist_flow': '14FRC509.MEAS',\n",
       "  'LN_dist_flow': '14FRC514.MEAS'},\n",
       " 'action_var': {'C1451_reflux ': '14FICA508.MEAS',\n",
       "  'Tray_5': '14TI528.PNT',\n",
       "  'C1452_reflux': '14FRCA513.MEAS',\n",
       "  'MPS_Steam': '14FRCA511.MEAS'},\n",
       " 'predict_var': '14FRC501.MEAS'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['14FIC015.MEAS', '16FIC501.MEAS', '14TI521.PNT', '14PRCA502.MEAS',\n",
       "       '14FRC509.MEAS', '14FRCA506.MEAS', '14TI504.PNT', '14TI532.PNT',\n",
       "       '14PRCA506.MEAS', '10FRCA505.MEAS', '14FICA508.MD', '14TRC515.MD',\n",
       "       '14FRCA513.MD', '14FRCA511.MD', '14TIC527.MEAS', '14QI506.PNT',\n",
       "       '14FRC514.OUT', '14FRC501.OUT', '14TI535.MEAS', '14TI528.PNT',\n",
       "       '14FRC514.MEAS', '14FRC501.MEAS', '14QI508.PNT', '14TY513.RO01',\n",
       "       '14FIC503.MEAS', '14TI502.PNT', '16Q001.PNT', '14QRA502.PNT',\n",
       "       '14Y559.RO01', '14LRCA503.MEAS'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "column_selector=[]\n",
    "short_actions=[]\n",
    "short_states=[]\n",
    "#first lets put all actions\n",
    "for key in var_dic['action_var']:\n",
    "    column_selector.append(var_dic['action_var'][key])\n",
    "print(len(column_selector))\n",
    "short_actions=deepcopy(column_selector) #safe all actions variables\n",
    "\n",
    "#second all states\n",
    "for key in var_dic['state_var']:\n",
    "    column_selector.append(var_dic['state_var'][key])\n",
    "    short_states.append(var_dic['state_var'][key]) #safe states\n",
    "    \n",
    "#third the optimization var\n",
    "column_selector.append(var_dic['predict_var']) \n",
    "short_states.append(var_dic['predict_var'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['14FICA508.MEAS', '14TI528.PNT', '14FRCA513.MEAS', '14FRCA511.MEAS', '16Q001.PNT', '14QRA502.PNT', '14QI506.PNT', '14QI508.PNT', '14FRC514.OUT', '14FRC501.OUT', '14FRC509.MEAS', '14FRC514.MEAS', '14FRC501.MEAS']\n",
      "column_selector 13\n",
      "short_actions 4\n",
      "short_states 9\n"
     ]
    }
   ],
   "source": [
    "print(column_selector)\n",
    "print('column_selector',len(column_selector))\n",
    "print('short_actions',len(short_actions))\n",
    "print('short_states',len(short_states))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create New Dataframe with smaler action-state-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short=vertical_stack[column_selector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>14FICA508.MEAS</th>\n",
       "      <th>14TI528.PNT</th>\n",
       "      <th>14FRCA513.MEAS</th>\n",
       "      <th>14FRCA511.MEAS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2169.806396</td>\n",
       "      <td>115.848541</td>\n",
       "      <td>2493.364014</td>\n",
       "      <td>16.972578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2165.187012</td>\n",
       "      <td>115.930305</td>\n",
       "      <td>2503.087891</td>\n",
       "      <td>16.983036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2134.303467</td>\n",
       "      <td>115.982369</td>\n",
       "      <td>2496.101807</td>\n",
       "      <td>16.995716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2144.191406</td>\n",
       "      <td>115.944038</td>\n",
       "      <td>2493.253662</td>\n",
       "      <td>17.020340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2152.655762</td>\n",
       "      <td>115.962944</td>\n",
       "      <td>2494.748047</td>\n",
       "      <td>17.034838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98636</td>\n",
       "      <td>2088.255127</td>\n",
       "      <td>114.624886</td>\n",
       "      <td>2259.743896</td>\n",
       "      <td>7.096138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98637</td>\n",
       "      <td>2091.254639</td>\n",
       "      <td>114.542984</td>\n",
       "      <td>2279.686279</td>\n",
       "      <td>7.112698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98638</td>\n",
       "      <td>2088.333008</td>\n",
       "      <td>114.477219</td>\n",
       "      <td>2278.392578</td>\n",
       "      <td>7.094784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98639</td>\n",
       "      <td>2089.855469</td>\n",
       "      <td>114.768044</td>\n",
       "      <td>2278.239990</td>\n",
       "      <td>7.069374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98640</td>\n",
       "      <td>2092.858887</td>\n",
       "      <td>114.558289</td>\n",
       "      <td>2280.760986</td>\n",
       "      <td>7.076496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2073588 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       14FICA508.MEAS  14TI528.PNT  14FRCA513.MEAS  14FRCA511.MEAS\n",
       "0         2169.806396   115.848541     2493.364014       16.972578\n",
       "1         2165.187012   115.930305     2503.087891       16.983036\n",
       "2         2134.303467   115.982369     2496.101807       16.995716\n",
       "3         2144.191406   115.944038     2493.253662       17.020340\n",
       "4         2152.655762   115.962944     2494.748047       17.034838\n",
       "...               ...          ...             ...             ...\n",
       "98636     2088.255127   114.624886     2259.743896        7.096138\n",
       "98637     2091.254639   114.542984     2279.686279        7.112698\n",
       "98638     2088.333008   114.477219     2278.392578        7.094784\n",
       "98639     2089.855469   114.768044     2278.239990        7.069374\n",
       "98640     2092.858887   114.558289     2280.760986        7.076496\n",
       "\n",
       "[2073588 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_short[short_actions]\n",
    "#df_short[short_states]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2073588, 13)\n",
      "C:/Users/aalbaher/dataset_pttgc/data_preprocess/May_13_165417/data_short.csv\n"
     ]
    }
   ],
   "source": [
    "csv_name='%sdata_short.csv'%(data_out_dir)\n",
    "df_short.to_csv(csv_name)\n",
    "print(df_short.shape)\n",
    "print(csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(2073587, 4)\n",
      "(2073587, 9)\n",
      "(2073587, 9)\n"
     ]
    }
   ],
   "source": [
    "#get arrays\n",
    "a_i=np.array(df_short[short_actions].iloc[0:len(df_short)-1,:]) #skip last row\n",
    "s_i=np.array(df_short[short_states].iloc[0:len(df_short)-1,:]) #skip last row\n",
    "s_o=np.array(df_short[short_states].iloc[1::,:]) #skip fist row\n",
    "print(len(short_actions))\n",
    "print(a_i.shape)\n",
    "print(s_i.shape)\n",
    "print(s_o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare output short list dataset\n",
    "x_set_short = np.concatenate((a_i,s_i),axis=1)\n",
    "y_set_short = s_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/aalbaher/dataset_pttgc/data_preprocess/May_13_165417/short_x.pickle\n",
      "C:/Users/aalbaher/dataset_pttgc/data_preprocess/May_13_165417/short_y.pickle\n",
      "(2073587, 13)\n",
      "(2073587, 9)\n"
     ]
    }
   ],
   "source": [
    "#writing dataset into disk\n",
    "x=('%sshort_x.pickle'%(data_out_dir))\n",
    "y=('%sshort_y.pickle'%(data_out_dir))\n",
    "with open(x, 'wb') as f:\n",
    "    pickle.dump(x_set_short, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(y, 'wb') as f:\n",
    "    pickle.dump(y_set_short, f, pickle.HIGHEST_PROTOCOL)\n",
    "print(x)\n",
    "print(y)\n",
    "print(x_set_short.shape)\n",
    "print(y_set_short.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shift_cut(actions,states,shift):\n",
    "    _,num_actions_columns=actions.shape\n",
    "    a_s_in=np.concatenate((actions,states),axis=1)\n",
    "    #print('a_s_shift\\n',a_s_in)\n",
    "    r,c=a_s_in.shape #rows, columns\n",
    "    n=r//shift\n",
    "    a_s_shift=np.zeros((n,c))\n",
    "    #print(a_s_shift.shape)\n",
    "    #print(n)\n",
    "    for i in range(1,n):\n",
    "        #print(i)\n",
    "        a_s_shift[i,:]=a_s_in[i*shift,:]\n",
    "    x_set=a_s_shift[0:-1,:]\n",
    "    y_set=a_s_shift[1::,num_actions_columns::]\n",
    "    return a_s_shift,x_set,y_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (414716, 13)\n",
      "y (414716, 9)\n"
     ]
    }
   ],
   "source": [
    "_,x_short_cut,y_short_cut=get_shift_cut(a_i,s_i,5)\n",
    "print('x',x_short_cut.shape)\n",
    "print('y',y_short_cut.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/aalbaher/dataset_pttgc/data_preprocess/May_13_165417/short_x_cut.pickle\n",
      "C:/Users/aalbaher/dataset_pttgc/data_preprocess/May_13_165417/short_y_cut.pickle\n"
     ]
    }
   ],
   "source": [
    "#safe cut data_set\n",
    "x=('%sshort_x_cut.pickle'%(data_out_dir))\n",
    "y=('%sshort_y_cut.pickle'%(data_out_dir))\n",
    "with open(x, 'wb') as f:\n",
    "    pickle.dump(x_short_cut, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(y, 'wb') as f:\n",
    "    pickle.dump(y_short_cut, f, pickle.HIGHEST_PROTOCOL)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(414716, 13)\n",
      "(414716, 9)\n"
     ]
    }
   ],
   "source": [
    "print(x_short_cut.shape)\n",
    "print(y_short_cut.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(s_i[0:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(s_o[0:3,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "short_states:\n",
      " ['16Q001.PNT', '14QRA502.PNT', '14QI506.PNT', '14QI508.PNT', '14FRC514.OUT', '14FRC501.OUT', '14FRC509.MEAS', '14FRC514.MEAS', '14FRC501.MEAS']\n",
      "short_actions\n",
      " ['14FICA508.MEAS', '14TI528.PNT', '14FRCA513.MEAS', '14FRCA511.MEAS']\n",
      "C:/Users/aalbaher/dataset_pttgc/data_preprocess/May_13_165417/short_states\n",
      "C:/Users/aalbaher/dataset_pttgc/data_preprocess/May_13_165417/short_actions\n"
     ]
    }
   ],
   "source": [
    "#Saving actions and state names for the reduced dataframe.\n",
    "f_ns='%sshort_states'%(data_out_dir)\n",
    "f_na='%sshort_actions'%(data_out_dir)\n",
    "print('short_states:\\n',short_states)\n",
    "print('short_actions\\n',short_actions)\n",
    "np.save(f_ns,short_states)\n",
    "np.save(f_na,short_actions)\n",
    "print(f_ns)\n",
    "print(f_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
